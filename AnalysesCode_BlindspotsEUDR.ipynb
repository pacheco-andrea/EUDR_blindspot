{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f5ec7e",
   "metadata": {},
   "source": [
    "# Filtering and saving INPE polygons between 2008 and 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86552365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import numpy as np\n",
    "\n",
    "# Load the shapefile\n",
    "shapefile_path = 'DIRECTORY_PATH/inpe_file.shp'\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Filter polygons with \"year\" greater than 2020\n",
    "filtered_gdf = gdf[(gdf['year'] >= 2008) & (gdf['year'] <= 2020)]\n",
    "\n",
    "# Save the filtered shapefile\n",
    "output_path = 'DIRECTORY_PATH/inpe_file_2008_2020.shp'\n",
    "filtered_gdf.to_file(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e059c",
   "metadata": {},
   "source": [
    "# Couting and summing area of INVALID polygons (based on missing information on geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd2d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load shapefile containing deforestation polygons\n",
    "deforest_polygons_path = 'DIRECTORY_PATH/inpe_file_2008_2020.shp'\n",
    "deforest_polygons = gpd.read_file(deforest_polygons_path)\n",
    "\n",
    "# Filter out invalid polygons\n",
    "invalid_deforest_polygons = deforest_polygons[~deforest_polygons.geometry.is_valid]\n",
    "\n",
    "# Calculate the sum of area_km for invalid geometries\n",
    "total_area_invalid = invalid_deforest_polygons['area_km'].sum()\n",
    "\n",
    "# Count the number of polygons with invalid geometries\n",
    "num_invalid_polygons = len(invalid_deforest_polygons)\n",
    "\n",
    "print(\"Total area of deforestation polygons with invalid geometry:\", total_area_invalid)\n",
    "print(\"Number of polygons with invalid geometry:\", num_invalid_polygons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3ac96",
   "metadata": {},
   "source": [
    "# Counting and summing area of VALID polygons (based on missing information on geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d657796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total area of deforestation polygons with valid geometry: 91517.30936652982\n",
      "Number of polygons with valid geometry: 552752\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load shapefile containing deforestation polygons\n",
    "deforest_polygons_path = 'DIRECTORY_PATH/inpe_file_2008_2020.shp'\n",
    "deforest_polygons = gpd.read_file(deforest_polygons_path)\n",
    "\n",
    "# Filter out valid polygons\n",
    "valid_deforest_polygons = deforest_polygons[deforest_polygons.geometry.is_valid]\n",
    "\n",
    "# Calculate the sum of area_km for valid geometries\n",
    "total_area_valid = valid_deforest_polygons['area_km'].sum()\n",
    "\n",
    "# Count the number of polygons with valid geometries\n",
    "num_valid_polygons = len(valid_deforest_polygons)\n",
    "\n",
    "print(\"Total area of deforestation polygons with valid geometry:\", total_area_valid)\n",
    "print(\"Number of polygons with valid geometry:\", num_valid_polygons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d3a3e",
   "metadata": {},
   "source": [
    "# Filtering and saving only valid polygons (based on missing information on geometries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a719fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load shapefile containing deforestation polygons\n",
    "deforest_polygons_path = 'DIRECTORY_PATH/inpe_file_2008_2020.shp'\n",
    "deforest_polygons = gpd.read_file(deforest_polygons_path)\n",
    "\n",
    "# Filter only valid polygons\n",
    "valid_deforest_polygons = deforest_polygons[deforest_polygons.geometry.is_valid]\n",
    "\n",
    "# Save the valid polygons to a new shapefile\n",
    "output_valid_shapefile_path = 'DIRECTORY_PATH/inpe_file_2008_2020_valid.shp'\n",
    "valid_deforest_polygons.to_file(output_valid_shapefile_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da4c4d4",
   "metadata": {},
   "source": [
    "# Adjusting CRS of the INPE deforestation polygons to fit the raster file from Soares-Filho et al. (2014) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1419ed2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import rasterio\n",
    "\n",
    "# Open the raster file to get its CRS and transform\n",
    "with rasterio.open('DIRECTORY_PATH/Soares-Filho_Suitability.tif') as src:\n",
    "    raster_crs = src.crs\n",
    "\n",
    "# Read the polygon shapefile\n",
    "gdf = gpd.read_file('DIRECTORY_PATH/inpe_file_2008_2020_valid.shp')\n",
    "\n",
    "# Reproject the shapefile to match the CRS and extent of the raster\n",
    "gdf_reprojected = gdf.to_crs(raster_crs)\n",
    "\n",
    "# Save the reprojected shapefile\n",
    "gdf_reprojected.to_file('DIRECTORY_PATH/inpe_file_2008_2020_valid_newCRS.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064527b",
   "metadata": {},
   "source": [
    "# Creating counts of Suitability pixels based on zonal_stats while considering only pixels entirely within the polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496cb4e2",
   "metadata": {},
   "source": [
    "# Summing deforested area by suitability category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "699da413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "# Load shapefile containing deforestation polygons\n",
    "deforest_polygons_path = 'DIRECTORY_PATH/inpe_file_2008_2020_valid_newCRS.shp'\n",
    "deforest_polygons = gpd.read_file(deforest_polygons_path)\n",
    "\n",
    "# Open the TIFF file\n",
    "suitabilityTIF_path = 'DIRECTORY_PATH/Soares-Filho_Suitability.tif'\n",
    "\n",
    "# Initialize counter for analyzed polygons\n",
    "analyzed_polygons_count = 0\n",
    "\n",
    "# Perform zonal statistics for all polygons\n",
    "for idx, polygon in deforest_polygons.iterrows():\n",
    "    try:\n",
    "        stats = zonal_stats(polygon.geometry, suitabilityTIF_path, nodata=255, all_touched=False, categorical=True)\n",
    "        # Print zone statistics for each polygon\n",
    "        for value, count in stats[0].items():\n",
    "            print(f\"Zone statistics for polygon {idx}: {value} - {count}\")\n",
    "        # Extract counts of each pixel value for the polygon and add them as new columns\n",
    "        for value, count in stats[0].items():\n",
    "            column_name = f'pixel_{value}'\n",
    "            if column_name not in deforest_polygons.columns:\n",
    "                deforest_polygons[column_name] = 0\n",
    "            deforest_polygons.at[idx, column_name] = count\n",
    "        # Count the number of pixels with nodata value and add it as a new column\n",
    "        nodata_count = stats[0].get(255, 0)\n",
    "        deforest_polygons.at[idx, 'pixel_mis'] = nodata_count\n",
    "        analyzed_polygons_count += 1\n",
    "        # Print message after values have been added as columns\n",
    "        print(f\"Values added as columns for polygon {idx}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping polygon {idx} due to geometry problems: {e}\")\n",
    "\n",
    "# Print the number of polygons analyzed\n",
    "print(f\"{analyzed_polygons_count} polygons analyzed.\")\n",
    "\n",
    "# Save the updated shapefile\n",
    "output_shapefile_path = 'DIRECTORY_PATH/inpe_file_2008_2020_valid_newCRS_ClassificationSuitability.shp'\n",
    "deforest_polygons.to_file(output_shapefile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a6a53f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total area_km in the shapefile: 91517.30936652982 \n",
      "Total area_km per Suit_Cat:\n",
      " Suit_Cat\n",
      "0    22056.312174\n",
      "1    53325.935360\n",
      "2    16135.061832\n",
      "Name: area_km, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Read the shapefile into a GeoDataFrame\n",
    "deforestation_agg = gpd.read_file('DIRECTORY_PATH/inpe_file_2008_2020_valid_newCRS_ClassificationSuitability.shp')\n",
    "\n",
    "# Create a new column 'New_Category' initialized with 0\n",
    "deforestation_agg['Suit_Cat'] = np.select(\n",
    "    [\n",
    "        (deforestation_agg['pixel_1'] > deforestation_agg['pixel_0']) & (deforestation_agg['pixel_1'] > deforestation_agg['pixel_2']),\n",
    "        (deforestation_agg['pixel_2'] > deforestation_agg['pixel_0']) & (deforestation_agg['pixel_2'] > deforestation_agg['pixel_1'])\n",
    "    ],\n",
    "    [\n",
    "        1,\n",
    "        2\n",
    "    ],\n",
    "    default=0\n",
    ")\n",
    "\n",
    "# Sort the DataFrame by year\n",
    "deforestation_agg.sort_values('year', inplace=True)\n",
    "\n",
    "total_area = deforestation_agg['area_km'].sum()\n",
    "total_area_per_suit_cat = deforestation_agg.groupby('Suit_Cat')['area_km'].sum()\n",
    "\n",
    "print(\"Total area_km in the shapefile:\", total_area,\n",
    "      \"\\nTotal area_km per Suit_Cat:\\n\", total_area_per_suit_cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fefad66",
   "metadata": {},
   "source": [
    "# Creating counts of Suitability pixels based on zonal_stats in the shapefile including legal and illegal classification (output from R code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe0d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "# Load shapefile containing deforestation polygons\n",
    "deforest_polygons_path = 'DIRECTORY_PATH/inpe_file_2008_2020_valid_legal&illegalclassification.shp'\n",
    "deforest_polygons = gpd.read_file(deforest_polygons_path)\n",
    "\n",
    "# Open the TIFF file\n",
    "suitabilityTIF_path = 'DIRECTORY_PATH/Soares-Filho_Suitability.tif'\n",
    "\n",
    "# Initialize counter for analyzed polygons\n",
    "analyzed_polygons_count = 0\n",
    "\n",
    "# Perform zonal statistics for all polygons\n",
    "for idx, polygon in deforest_polygons.iterrows():\n",
    "    try:\n",
    "        stats = zonal_stats(polygon.geometry, suitabilityTIF_path, nodata=255, all_touched=False, categorical=True)\n",
    "        # Print zone statistics for each polygon\n",
    "        for value, count in stats[0].items():\n",
    "            print(f\"Zone statistics for polygon {idx}: {value} - {count}\")\n",
    "        # Extract counts of each pixel value for the polygon and add them as new columns\n",
    "        for value, count in stats[0].items():\n",
    "            column_name = f'pixel_{value}'\n",
    "            if column_name not in deforest_polygons.columns:\n",
    "                deforest_polygons[column_name] = 0\n",
    "            deforest_polygons.at[idx, column_name] = count\n",
    "        # Count the number of pixels with nodata value and add it as a new column\n",
    "        nodata_count = stats[0].get(255, 0)\n",
    "        deforest_polygons.at[idx, 'pixel_mis'] = nodata_count\n",
    "        analyzed_polygons_count += 1\n",
    "        # Print message after values have been added as columns\n",
    "        print(f\"Values added as columns for polygon {idx}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping polygon {idx} due to geometry problems: {e}\")\n",
    "\n",
    "# Print the number of polygons analyzed\n",
    "print(f\"{analyzed_polygons_count} polygons analyzed.\")\n",
    "\n",
    "# Save the updated shapefile\n",
    "output_shapefile_path = 'DIRECTORY_PATH/inpe_file_2008_2020_valid_legal&illegalclassification_ClassificationSuitability.shp'\n",
    "deforest_polygons.to_file(output_shapefile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059c522",
   "metadata": {},
   "source": [
    "# Summing deforested area by suitability and legality category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe2ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Read the shapefile\n",
    "shapefile2 = gpd.read_file('DIRECTORY_PATH/inpe_file_2008_2020_valid_legal&illegalclassification_ClassificationSuitability.shp')\n",
    "\n",
    "# Define conditions for filtering\n",
    "legal_soy_suitable = (shapefile2['legality'] == 'legal') & ((shapefile2['pixel_1'] > shapefile2['pixel_0']) | (shapefile2['pixel_2'] > shapefile2['pixel_0']))\n",
    "illegal_soy_suitable = (shapefile2['legality'] == 'illegal') & ((shapefile2['pixel_1'] > shapefile2['pixel_0']) | (shapefile2['pixel_2'] > shapefile2['pixel_0']))\n",
    "legal_not_soy_suitable = (shapefile2['legality'] == 'legal') & ~((shapefile2['pixel_1'] > shapefile2['pixel_0']) | (shapefile2['pixel_2'] > shapefile2['pixel_0']))\n",
    "illegal_not_soy_suitable = (shapefile2['legality'] == 'illegal') & ~((shapefile2['pixel_1'] > shapefile2['pixel_0']) | (shapefile2['pixel_2'] > shapefile2['pixel_0']))\n",
    "\n",
    "# Filter shapefile2 for each condition\n",
    "legal_soy_suitable_deforestation = shapefile2[legal_soy_suitable]\n",
    "illegal_soy_suitable_deforestation = shapefile2[illegal_soy_suitable]\n",
    "legal_not_soy_suitable_deforestation = shapefile2[legal_not_soy_suitable]\n",
    "illegal_not_soy_suitable_deforestation = shapefile2[illegal_not_soy_suitable]\n",
    "\n",
    "# Calculate total deforestation for each category\n",
    "total_legal_soy_suitable = legal_soy_suitable_deforestation['area'].sum()\n",
    "total_illegal_soy_suitable = illegal_soy_suitable_deforestation['area'].sum()\n",
    "total_legal_not_soy_suitable = legal_not_soy_suitable_deforestation['area'].sum()\n",
    "total_illegal_not_soy_suitable = illegal_not_soy_suitable_deforestation['area'].sum()\n",
    "\n",
    "# Print the totals\n",
    "print(\"Total Deforestation per Category:\")\n",
    "print(f\"Soy Suitable and Legal: {total_legal_soy_suitable} km²\")\n",
    "print(f\"Soy Suitable and Illegal: {total_illegal_soy_suitable} km²\")\n",
    "print(f\"Not Soy Suitable and Legal: {total_legal_not_soy_suitable} km²\")\n",
    "print(f\"Not Soy Suitable and Illegal: {total_illegal_not_soy_suitable} km²\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
